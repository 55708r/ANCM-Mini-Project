{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpsS5soZTAsse3x+ZL8Cwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/55708r/ANCM-Mini-Project/blob/main/Simple_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEQQI6o9ejAB"
      },
      "source": [
        "#Import the libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOEyemHez8M"
      },
      "source": [
        "features = (np.random.randint(10, size=(100, 1)))\n",
        "print(features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l8v7Po6e0tn"
      },
      "source": [
        "training_dataset_length = math.ceil(len(features) * .75)\n",
        "print(training_dataset_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68ydH5lfe3Yv"
      },
      "source": [
        "#Scale the all of the data to be values between 0 and 1 \n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
        "scaled_data = scaler.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMxrGL0Ue5cq"
      },
      "source": [
        "train_data = scaled_data[0:training_dataset_length  , : ]\n",
        "\n",
        "#Splitting the data\n",
        "x_train=[]\n",
        "y_train = []\n",
        "\n",
        "for i in range(10, len(train_data)):\n",
        "    x_train.append(train_data[i-10:i,0])\n",
        "    y_train.append(train_data[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNkv03Zte-X0"
      },
      "source": [
        "#Convert to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "#Reshape the data into 3-D array\n",
        "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04KbmXoXfFcn"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Initialising the RNN\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and Dropout layer\n",
        "model.add(LSTM(units = 50, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and Dropout layer\n",
        "model.add(LSTM(units = 50, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and and Dropout layer\n",
        "model.add(LSTM(units = 50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "# For Full connection layer we use dense\n",
        "# As the output is 1D so we use unit=1\n",
        "model.add(Dense(units = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLd4wHDOfGMj"
      },
      "source": [
        "#compile and fit the model on 30 epochs\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "model.fit(x_train, y_train, epochs = 30, batch_size = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8u7el2efIqH"
      },
      "source": [
        "#Test data set\n",
        "test_data = scaled_data[training_dataset_length - 10: , : ]\n",
        "\n",
        "#splitting the x_test and y_test data sets\n",
        "x_test = []\n",
        "y_test =  features[training_dataset_length : , : ] \n",
        "\n",
        "for i in range(10,len(test_data)):\n",
        "    x_test.append(test_data[i-10:i,0])\n",
        "    \n",
        "#Convert x_test to a numpy array \n",
        "x_test = np.array(x_test)\n",
        "\n",
        "#Reshape the data into 3-D array\n",
        "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vvgvwN-frA0"
      },
      "source": [
        "#check predicted values\n",
        "predictions = model.predict(x_test) \n",
        "#Undo scaling\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "#Calculate RMSE score\n",
        "rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}